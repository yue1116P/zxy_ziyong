# 深度学习基础
## 各模型适用领域
- ResNet：图像分类
- U-Net：图像分割
- YOLO：目标检测
- 

# Stable Diffusion
## 核心基础原理
1.工作流程
- CLIP Text Encoder将文本信息进行编码生成对应的Text Embeddings特征矩阵
- 文生图：用random函数生成一个高斯噪声矩阵作为Latent Feature（隐空间特征）的“替代”
- 图生图：将原图片通过图像编码器（VAE Encoder）生成Latent Feature作为输入。
- Latent Feature输入到“图像优化模块”中，并通过Text Embeddings特征矩阵进行优化的“控制”
- <img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/5c3a53ac-ee4e-4ade-afb2-8a486943cad1" />
    
2.图像优化模块
- 由一个U-Net网络和一个Schedule算法共同组成
  - U-Net网络：预测噪声，不断优化生成过程，在预测噪声的同时不断注入文本语义信息
  - chedule算法对每次U-Net预测的噪声进行优化处理（动态调整预测的噪声，控制U-Net预测噪声的强度），从而统筹生成过程的进度。
-<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/995a9a41-cb91-4fd1-a34c-04392d9ca3cf" />
