# 深度学习基础
## 各模型适用领域
- ResNet：图像分类
- U-Net：图像分割
- YOLO：目标检测
- 
---
# Stable Diffusion
## 核心基础原理
### 工作流程
1.过程
- CLIP Text Encoder将文本信息进行编码生成对应的Text Embeddings特征矩阵
- 文生图：用random函数生成一个高斯噪声矩阵作为Latent Feature（隐空间特征）的“替代”
- 图生图：将原图片通过图像编码器（VAE Encoder）生成Latent Feature作为输入。
- Latent Feature输入到“图像优化模块”中，并通过Text Embeddings特征矩阵进行优化的“控制”
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/5c3a53ac-ee4e-4ade-afb2-8a486943cad1" />  

2.图像优化模块
- 由一个U-Net网络和一个Schedule算法共同组成
  - U-Net网络：预测噪声，不断优化生成过程，在预测噪声的同时不断注入文本语义信息
  - Schedule算法对每次U-Net预测的噪声进行优化处理（动态调整预测的噪声，控制U-Net预测噪声的强度），从而统筹生成过程的进度。
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/995a9a41-cb91-4fd1-a34c-04392d9ca3cf" />  

3.图像解码器
- 图像优化后，将优化迭代后的Latent Feature输入到图像解码器（VAE Decoder）中，将Latent Feature重建成像素级图像。
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/3c035cac-7dd9-4796-a881-9d65a2febf92" />
- 左侧是初始Latent Feature经过图像解码器重建后的图片，显然是一个纯噪声图片；上图右侧是经过SD的“图像优化模块”处理后，再用图像解码器重建出来的图片，可以看到是一张包含丰富内容信息的有效图片。

4.前向推理流程图
<img width="1000" height="500" alt="image" src="https://github.com/user-attachments/assets/b7c38b12-dd3d-4bb0-ad95-faee60a2ab81" />

### 核心基础原理
1.对比GAN
- 一致的是，SD模型同样拟合训练集分布，并能够生成与训练集分布相似的输出结果
- SD模型训练过程更稳定，而且具备更强的泛化性能。
- 归功于扩散模型中核心的前向扩散过程（Forward Diffusion Process）和反向扩散过程（Reverse Diffusion Process）

2.详解
- 无论是前向扩散过程还是反向扩散过程都是一个参数化的马尔可夫链（Markov chain）[原论文](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2006.11239.pdf)
<img width="1440" height="276" alt="image" src="https://github.com/user-attachments/assets/35479783-a88a-4f93-8db5-4ee11fabf6e6" />
- 前向扩散过程是固定的，由Schedule算法进行统筹控制<br>
  - 可以基于初始数据X0和任意的扩散步数Ki,采样得到对应的数据Xi
- 反向扩散过程中每一步预测并去除的噪声分布，都需要扩散模型在训练中学习。
- 训练目标：将扩散模型每次预测出的噪声和每次实际加入的噪声做回归，让扩散模型能够准确的预测出每次实际加入的真实噪声。
<img width="720" height="992" alt="image" src="https://github.com/user-attachments/assets/75ace0f9-4641-4598-b2a3-4c5a47eca989" />
