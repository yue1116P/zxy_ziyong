# 通用
## 先谷歌查，查不到再问AI

## conda install卡在solving environment不动
- https://github.com/conda/conda/issues/11919
- 使用Libmamba这个依赖项求解器
  - 更新base环境conda：conda update -n base conda 
  - 安装libmamba并在conda config中设置，这样在自己创建的虚拟环境中也可以使用：
  - conda install -n base conda-libmamba-solver
  - conda config --set solver libmamba

# UNET
## undefined symbol: iJIT_NotifyEvent
- from torch._C import *  # noqa: F403  
……  
undefined symbol: iJIT_NotifyEvent
  - 错误原因：mkl包版本不匹配，conda和pip使用不同的MKL版本。  
  - 解决方法：对mkl进行降级 conda install mkl=2024.0
    - pip install mkl==2024.0.0

## Could not load library libcudnn_cnn_infer.so.8.
- Error: libnvrtc.so: cannot open shared object file: No such file or directory
- 安装nvcc驱动(在用户环境下而非虚拟环境)
  - conda install nvidia-cuda-toolkit
    - sudo apt install nvidia-cuda-toolkit

# YOLOV10
## Gradio Space Crashing on Startup - TypeError: argument of type ‘bool’ is not iterable
- 更新gradio：pip install --upgrade gradio
- 更新gradio ultralytics：pip install --upgrade gradio ultralytics
- pydantic==2.10.6

# ControlNet
## OSError: You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull`
- ControlNet 仓库中缺少大文件（例如模型权重），因为这些文件是通过 Git LFS（Large File Storage） 管理的
- 我自己出现该问题的原因是通过zip下载的，并非是一个Git仓库，缺少.git信息，无法通过LFS来拉取所需的模型
- 使用克隆原仓库的方法部署

## python -c "import torch; print(torch.cuda.is_available())"--------False
- 如果nvidia-smi输出信息正常，那可能是Pytorch安装成cpu版本了
  - python -c "import torch; print(torch.__version__); print(torch.version.cuda)"
  - 1.12.1
  - None----这说明是安装的CPU版本
- 卸载重装Pytorch
  - pip uninstall -y torch torchvision torchaudio
- 根据项目所需版本重新安装

## File "...site-packages\gradio\queueing.py", line 298, in call_prediction---------assert data is not None, "No event data"
- 默认安装的gradio版本为3.x,官方已停止维护，需要更新gradio版本
  - gradio更新后有许多参数变更，需要手动修改

## RuntimeError: Error(s) in loading state_dict for ControlLDM:Unexpected key(s) in state_dict: "cond_stage_model.transformer.text_model.embeddings.position_ids". 
- Checkpoint文件里包含了一个名为cond_stage_model.transformer.text_model.embeddings.position_ids 的键值（Key）。这通常是 CLIP Text Encoder 的一部分。 但是，当前的ControlLDM代码（基于旧版 Stable Diffusion 架构）在初始化模型时，并不期望加载这个position_ids。这是因为在较新的 transformers 版本中，position_ids 被作为 persistent buffer 保存了下来，而旧版代码认为它是临时生成的，不需要保存。
- 添加strict=False，允许模型忽略多余的position_ids键值
  - model.load_state_dict(load_state_dict('./lightning_logs/version_10/checkpoints/epoch=3-step=1895.ckpt', location='cuda'), strict=False)
